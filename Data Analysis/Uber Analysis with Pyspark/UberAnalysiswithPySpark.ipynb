{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fce1aef-3108-4b98-bd9a-4fdf41174740",
   "metadata": {},
   "source": [
    "The goal of the project is to utilize Python’s powerful library for big data processing to gain insights from Uber’s dataset and answer questions below. \n",
    "Data sets and analysis questions are from\n",
    "<a href=\"https://www.kaggle.com/datasets/nanasahebshinde/uber-case-study\">Kaggle’s Uber Case Study</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128ae69-16a3-4e4d-83e1-4b92d0bcfdab",
   "metadata": {},
   "source": [
    "<b>Dataset Columns</b>:<br>\n",
    "Date<br>\n",
    "Time<br>\n",
    "Eyeballs = Customers who launch the app looking for riders. It is a good measure of demand<br>\n",
    "Zeroes = Customers who open the app and see no cars in the area.<br>\n",
    "Requests = Customers who make requests for a car.<br>\n",
    "Completed Trip = The point from when a customer is picked<br>\n",
    "Unique Drivers<br><br>\n",
    "\n",
    "<b>Using the provided dataset, answer the following questions</b>:\n",
    "1. Which date had the most trips completed?<br>\n",
    "2. What was the highest number of completed trips within a 24 hour period?<br>\n",
    "3. Which hour of the day had the most requests during?<br>\n",
    "4. What percentages of all zeroes occurred on weekends (Friday at 5 pm to Sunday at 3 am)?<br>\n",
    "5. In drafting a driver schedule in terms of 8 hour shifts, when are the busiest 8 consecutive hours in terms of unique requests? A new shift starts every 8 hours. Assume that a driver will work the same shift each day.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422a78cb-986b-4de8-bea9-a1b824f52741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the findspark module, initialize the module, and import pyspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6025b7fb-fc90-486a-88aa-3d79c57f6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as sf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"MyUberData\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba354632-a2a4-4249-b8dd-9094e8ac4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df = spark.read.csv(\"uber_dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb3cef26-7b25-4dd0-aa1f-0dea11e01905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Time (Local)',\n",
       " 'Eyeballs ',\n",
       " 'Zeroes ',\n",
       " 'Completed Trips ',\n",
       " 'Requests ',\n",
       " 'Unique Drivers']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc281a4b-2a2a-4cdb-8490-150023c086fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+-------+----------------+---------+--------------+\n",
      "|     Date|Time (Local)|Eyeballs |Zeroes |Completed Trips |Requests |Unique Drivers|\n",
      "+---------+------------+---------+-------+----------------+---------+--------------+\n",
      "|10-Sep-12|           7|        5|      0|               2|        2|             9|\n",
      "|10-Sep-12|           8|        6|      0|               2|        2|            14|\n",
      "|10-Sep-12|           9|        8|      3|               0|        0|            14|\n",
      "|10-Sep-12|          10|        9|      2|               0|        1|            14|\n",
      "|10-Sep-12|          11|       11|      1|               4|        4|            11|\n",
      "|10-Sep-12|          12|       12|      0|               2|        2|            11|\n",
      "|10-Sep-12|          13|        9|      1|               0|        0|             9|\n",
      "|10-Sep-12|          14|       12|      1|               0|        0|             9|\n",
      "|10-Sep-12|          15|       11|      2|               1|        2|             7|\n",
      "|10-Sep-12|          16|       11|      2|               3|        4|             6|\n",
      "|10-Sep-12|          17|       12|      2|               3|        4|             4|\n",
      "|10-Sep-12|          18|       11|      1|               3|        4|             7|\n",
      "|10-Sep-12|          19|       13|      2|               2|        3|             7|\n",
      "|10-Sep-12|          20|       11|      1|               0|        0|             5|\n",
      "|10-Sep-12|          21|       11|      0|               1|        1|             3|\n",
      "|10-Sep-12|          22|       16|      3|               0|        2|             4|\n",
      "|10-Sep-12|          23|       21|      5|               3|        3|             4|\n",
      "|11-Sep-12|           0|        9|      3|               1|        1|             3|\n",
      "|11-Sep-12|           1|        3|      2|               0|        1|             3|\n",
      "|11-Sep-12|           2|        1|      1|               0|        0|             1|\n",
      "+---------+------------+---------+-------+----------------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a9287a-e421-4905-8a7b-63a849d4e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22-Sep-12 with 248 trips has the most number of trips.\n"
     ]
    }
   ],
   "source": [
    "# Which date had the most trips completed?\n",
    "#To answer this question, we will sum up completed trips by date, sort in descending order and select top row\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# Group the data by date and sum the completed trips\n",
    "completed_trips_by_date = df.groupBy(\"Date\").sum(\"Completed Trips \")\n",
    "\n",
    "# Find the date with the most completed trips\n",
    "date_with_most_completed_trips = completed_trips_by_date \\\n",
    "    .orderBy(sum(\"Completed Trips \"), ascending=False)\n",
    "\n",
    "print(f'{date_with_most_completed_trips.first()[0]} with {date_with_most_completed_trips.first()[1]} trips has the most number of trips.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49e2c9dc-d016-4f28-8617-b1bcbc54c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+-------+----------------+---------+--------------+------------+-------------------+-------------------+\n",
      "|     Date|Time (Local)|Eyeballs |Zeroes |Completed Trips |Requests |Unique Drivers| joined_date|       datetime_srt|           Datetime|\n",
      "+---------+------------+---------+-------+----------------+---------+--------------+------------+-------------------+-------------------+\n",
      "|10-Sep-12|           7|        5|      0|               2|        2|             9| 10-Sep-12 7|09-10-2012 07:00:00|2012-09-10 07:00:00|\n",
      "|10-Sep-12|           8|        6|      0|               2|        2|            14| 10-Sep-12 8|09-10-2012 08:00:00|2012-09-10 08:00:00|\n",
      "|10-Sep-12|           9|        8|      3|               0|        0|            14| 10-Sep-12 9|09-10-2012 09:00:00|2012-09-10 09:00:00|\n",
      "|10-Sep-12|          10|        9|      2|               0|        1|            14|10-Sep-12 10|09-10-2012 10:00:00|2012-09-10 10:00:00|\n",
      "|10-Sep-12|          11|       11|      1|               4|        4|            11|10-Sep-12 11|09-10-2012 11:00:00|2012-09-10 11:00:00|\n",
      "|10-Sep-12|          12|       12|      0|               2|        2|            11|10-Sep-12 12|09-10-2012 12:00:00|2012-09-10 12:00:00|\n",
      "|10-Sep-12|          13|        9|      1|               0|        0|             9|10-Sep-12 13|09-10-2012 13:00:00|2012-09-10 13:00:00|\n",
      "|10-Sep-12|          14|       12|      1|               0|        0|             9|10-Sep-12 14|09-10-2012 14:00:00|2012-09-10 14:00:00|\n",
      "|10-Sep-12|          15|       11|      2|               1|        2|             7|10-Sep-12 15|09-10-2012 15:00:00|2012-09-10 15:00:00|\n",
      "|10-Sep-12|          16|       11|      2|               3|        4|             6|10-Sep-12 16|09-10-2012 16:00:00|2012-09-10 16:00:00|\n",
      "|10-Sep-12|          17|       12|      2|               3|        4|             4|10-Sep-12 17|09-10-2012 17:00:00|2012-09-10 17:00:00|\n",
      "|10-Sep-12|          18|       11|      1|               3|        4|             7|10-Sep-12 18|09-10-2012 18:00:00|2012-09-10 18:00:00|\n",
      "|10-Sep-12|          19|       13|      2|               2|        3|             7|10-Sep-12 19|09-10-2012 19:00:00|2012-09-10 19:00:00|\n",
      "|10-Sep-12|          20|       11|      1|               0|        0|             5|10-Sep-12 20|09-10-2012 20:00:00|2012-09-10 20:00:00|\n",
      "|10-Sep-12|          21|       11|      0|               1|        1|             3|10-Sep-12 21|09-10-2012 21:00:00|2012-09-10 21:00:00|\n",
      "|10-Sep-12|          22|       16|      3|               0|        2|             4|10-Sep-12 22|09-10-2012 22:00:00|2012-09-10 22:00:00|\n",
      "|10-Sep-12|          23|       21|      5|               3|        3|             4|10-Sep-12 23|09-10-2012 23:00:00|2012-09-10 23:00:00|\n",
      "|11-Sep-12|           0|        9|      3|               1|        1|             3| 11-Sep-12 0|09-11-2012 00:00:00|2012-09-11 00:00:00|\n",
      "|11-Sep-12|           1|        3|      2|               0|        1|             3| 11-Sep-12 1|09-11-2012 01:00:00|2012-09-11 01:00:00|\n",
      "|11-Sep-12|           2|        1|      1|               0|        0|             1| 11-Sep-12 2|09-11-2012 02:00:00|2012-09-11 02:00:00|\n",
      "+---------+------------+---------+-------+----------------+---------+--------------+------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert Date and Hour fields in Datetime field\n",
    "#Concatenate Date string and Hour string in the new column\n",
    "df = df.withColumn('joined_date', sf.concat(sf.col('Date'),sf.lit(' '), sf.col('Time (Local)')))\n",
    "#Use unit_timestamp converstion to get Datetime in string format\n",
    "df = df.withColumn('datetime_srt', from_unixtime(unix_timestamp('joined_date', 'd-LLL-yy H'),'MM-dd-yyyy HH:mm:ss'))\n",
    "#Convert string into DateTime type\n",
    "df=df.withColumn('Datetime', sf.to_timestamp('datetime_srt','MM-dd-yyyy HH:mm:ss'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daca726a-a4e2-4604-900a-4501547e2c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|              window|Total Completed Trips|\n",
      "+--------------------+---------------------+\n",
      "|{2012-09-21 19:00...|                  256|\n",
      "|{2012-09-22 19:00...|                  189|\n",
      "|{2012-09-14 19:00...|                  181|\n",
      "|{2012-09-15 19:00...|                  161|\n",
      "|{2012-09-20 19:00...|                  130|\n",
      "|{2012-09-11 19:00...|                   96|\n",
      "|{2012-09-13 19:00...|                   63|\n",
      "|{2012-09-16 19:00...|                   51|\n",
      "|{2012-09-17 19:00...|                   47|\n",
      "|{2012-09-19 19:00...|                   46|\n",
      "|{2012-09-18 19:00...|                   42|\n",
      "|{2012-09-12 19:00...|                   40|\n",
      "|{2012-09-10 19:00...|                   24|\n",
      "|{2012-09-09 19:00...|                   20|\n",
      "|{2012-09-23 19:00...|                   19|\n",
      "+--------------------+---------------------+\n",
      "\n",
      "The highest number of completed trips in 24 hour period is 256\n"
     ]
    }
   ],
   "source": [
    "#What was the highest number of completed trips within a 24 hour period?\n",
    "\n",
    "\n",
    "# Group the data by 24-hour windows and sum the completed trips\n",
    "completed_trips_by_window = df \\\n",
    "    .groupBy(sf.window(\"Datetime\", \"24 hours\")) \\\n",
    "    .agg(sum(\"Completed Trips \").alias(\"Total Completed Trips\")) \\\n",
    "    .orderBy(\"Total Completed Trips\", ascending=False)\n",
    "\n",
    "\n",
    "completed_trips_by_window.show()\n",
    "\n",
    "highest_completed_trips_in_24_hours = completed_trips_by_window \\\n",
    "    .select(\"Total Completed Trips\") \\\n",
    "    .first()[\"Total Completed Trips\"]\n",
    "\n",
    "print(f'The highest number of completed trips in 24 hour period is {highest_completed_trips_in_24_hours}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e37c6f9d-ebc8-4f60-87ac-c3e6b99f120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hour with the most requests is: 23\n"
     ]
    }
   ],
   "source": [
    "#Which hour of the day had the most requests?\n",
    "hourly_requests = df \\\n",
    "    .groupBy(sf.hour(\"Datetime\").alias(\"hour\")) \\\n",
    "    .agg(sum(\"Requests \").alias(\"total_requests\")) \\\n",
    "    .orderBy(\"total_requests\", ascending=False)\n",
    "\n",
    "most_requested_hour = hourly_requests.select(\"hour\").first()[0]\n",
    "print(\"The hour with the most requests is:\", most_requested_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f780f081-3396-480c-91f2-3260a10cb6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of \"Zero\" events that occurred on weekends is:  29.111266620014 %\n"
     ]
    }
   ],
   "source": [
    "#What percentages of all zeroes occurred on weekends (Friday at 5 pm to Sunday at 3 am)?\n",
    "\n",
    "#First, let's calculate number of \"Zeros\" occurred on the weekend\n",
    "weekend_zeros = df.filter((hour(\"Datetime\") >= 17) | (hour(\"Datetime\") < 3)) \\\n",
    "    .filter((dayofweek(\"Datetime\") == 6) | (dayofweek(\"Datetime\") == 7)) \\\n",
    "    .agg(sum(\"Zeroes \").alias(\"weekend_zeros\")).collect()[0][\"weekend_zeros\"]\n",
    "\n",
    "#Then, let's calculate total number of \"Zero\" incidents in the dataset\n",
    "total_zeros = df.agg(sum(\"Zeroes \").alias(\"total_zeros\")).collect()[0][\"total_zeros\"]\n",
    "\n",
    "pcnt_weekend_zeros = weekend_zeros / total_zeros * 100\n",
    "\n",
    "print(\"The percentage of \\\"Zero\\\" events that occurred on weekends is: \", pcnt_weekend_zeros, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "957d5724-dad4-4787-be5e-f6316b4f30e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n",
      "|date_format(window.start, yyyy-MM-dd HH:mm)|\n",
      "+-------------------------------------------+\n",
      "|                           2012-09-22 19:00|\n",
      "+-------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-----------------------------------------+\n",
      "|date_format(window.end, yyyy-MM-dd HH:mm)|\n",
      "+-----------------------------------------+\n",
      "|                         2012-09-23 03:00|\n",
      "+-----------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question: In drafting a driver schedule in terms of 8 hours shifts, when are the busiest 8 consecutive hours in terms of unique requests? \n",
    "# A new shift starts every 8 hours. Assume that a driver will work the same shift each day.\n",
    "\n",
    "#First, we will find the number of unique requests per hour of each day. Then create a window of 8 hours to find 8 consecutive hours\n",
    "#with the highest number of unique requests. \n",
    "\n",
    "import re\n",
    "\n",
    "busiest_8_consecutive_hours = df \\\n",
    "    .groupBy(sf.window(\"Datetime\", \"8 hours\")) \\\n",
    "    .agg(sum(\"Requests \").alias(\"total_requests\")) \\\n",
    "    .orderBy(sum(\"Requests \"), ascending=False)\n",
    "\n",
    "start_date = busiest_8_consecutive_hours.select(sf.date_format(sf.col('window.start'), 'yyyy-MM-dd HH:mm'))\n",
    "\n",
    "start_date.show(1)\n",
    "\n",
    "end_date = busiest_8_consecutive_hours.select(sf.date_format(sf.col('window.end'), 'yyyy-MM-dd HH:mm'))\n",
    "end_date.show(1)\n",
    "\n",
    "#.str.extract(r'\"start\":\"([^\"]*)\",\"end\":\"([^\"]+)')\n",
    "\n",
    "#print(\"the busiest 8 consecutive hours are from\", start_date )\n",
    "#, \" to \",\n",
    "#      busiest_8_consecutive_hours.collect()[0](\"end\"), \" with \", busiest_8_consecutive_hours.collect()[0](\"total_requests\"), \n",
    "#      \" total requests\")\n",
    "#print(busiest_8_consecutive_hours.collect()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f8b87-79c6-4314-9f79-e46a9ff1cb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenv",
   "language": "python",
   "name": "jupyterenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
